{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Anchor Backend GPU API\n",
        "\n",
        "Purposes: Run inference on AI model, generate Manim animation gifs."
      ],
      "metadata": {
        "id": "ebVHxyDcyocz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cP26yyYOn96j"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install opencv-python\n",
        "!pip install pix2tex\n",
        "!pip install fastapi\n",
        "!pip install fastapi nest-asyncio pyngrok uvicorn\n",
        "!pip install --upgrade google-cloud-storage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!sudo apt update\n",
        "!sudo apt install libcairo2-dev ffmpeg \\\n",
        "    texlive texlive-latex-extra texlive-fonts-extra \\\n",
        "    texlive-latex-recommended texlive-science \\\n",
        "    tipa libpango1.0-dev\n",
        "!pip install manim\n",
        "!pip install IPython --upgrade"
      ],
      "metadata": {
        "id": "BpcM7n1SXC-z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-0sbU3AnUXG1"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import matplotlib.pyplot as plt\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\"\"\"\n",
        "Uses cv2 to find a red box \n",
        "Return a dictionary:\n",
        "  {'box': [(top left point), (bottom right point)]\n",
        "   'image': path to an isolated image of the equation\n",
        "  }\n",
        "\"\"\"\n",
        "def get_eqn(img):\n",
        "  img_hsv=cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "  # lower mask (0-10)\n",
        "  lower_red = np.array([0,50,50])\n",
        "  upper_red = np.array([10,255,255])\n",
        "  mask0 = cv2.inRange(img_hsv, lower_red, upper_red)\n",
        "  # upper mask (170-180)\n",
        "  lower_red = np.array([170,50,50])\n",
        "  upper_red = np.array([180,255,255])\n",
        "  mask1 = cv2.inRange(img_hsv, lower_red, upper_red)\n",
        "  # join my masks\n",
        "  mask = mask0+mask1\n",
        "  # set my output img to zero everywhere except my mask\n",
        "  output_img = img.copy()\n",
        "  output_img[np.where(mask==0)] = 0\n",
        "  bool_image = mask.astype(bool)\n",
        "  x, y = np.where(bool_image)  # get the indices (x, y) where the image is True\n",
        "  # get top left and bottom right corners of red box\n",
        "  map = {(x_i) + (y_i): (x_i, y_i) for x_i, y_i in zip(x, y)}\n",
        "  bottom_right = max(map.keys())\n",
        "  x_right, y_right = map[bottom_right]\n",
        "  top_left = min(map.keys())\n",
        "  x_left, y_left = map[top_left]\n",
        "\n",
        "  box = img[x_left:x_right, y_left:y_right] # crop out box\n",
        "\n",
        "  # remove any of the border we may have grabbed (keep only black pixels)\n",
        "  for x in range(0, x_right-x_left):\n",
        "    for y in range(0, y_right-y_left):\n",
        "      if(max(box[x][y]) > 50):\n",
        "        box[x][y] = (255,255,255)\n",
        "  \n",
        "  cv2.imwrite('output.jpeg', box)\n",
        "  return {'box': [(x_left, y_left),(x_right, y_right)], 'image': 'output.jpeg'} # hardcoded now, will be multiple boxes later\n",
        "\n",
        "# Run our fine tuned model on \n",
        "def image_to_latex(eqn_path):\n",
        "  model_output = subprocess.check_output(['pix2tex', 'output.jpeg', '--checkpoint', '/content/mixed_e03_step16297 (2).pth']).decode(\"utf-8\")\n",
        "  print(model_output)\n",
        "  parsed_model_output = model_output.split(':')[1].replace('\\n', '').replace(' ', '').lower()\n",
        "  return parsed_model_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kVzWhaSjdvQ-"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Uses cv2 to extract the blue bordered region where we will put the graph\n",
        "Returns [(top left point),(bottom right point)]\n",
        "\"\"\"\n",
        "def get_graph_box(img):\n",
        "  img_hsv=cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "  lower_blue = np.array([101,50,38])\n",
        "  upper_blue = np.array([110,255,255])  \n",
        "  mask = cv2.inRange(img_hsv, lower_blue, upper_blue)\n",
        "  output_img = img.copy()\n",
        "  output_img[np.where(mask==0)] = 0\n",
        "  bool_image = mask.astype(bool)\n",
        "  x, y = np.where(bool_image)  # get the indices (x, y) where the image is True\n",
        "  # get top left and bottom right corners of red box\n",
        "  map = {(x_i) + (y_i): (x_i, y_i) for x_i, y_i in zip(x, y)}\n",
        "  bottom_right = max(map.keys())\n",
        "  x_right, y_right = map[bottom_right]\n",
        "  top_left = min(map.keys())\n",
        "  x_left, y_left = map[top_left]\n",
        "  return [(x_left, y_left),(x_right, y_right)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "OanhJmAbSmYe"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_latex(image_path):\n",
        "  img = cv2.imread(image_path)\n",
        "  eqn_data = get_eqn(img)\n",
        "  eqn_box = eqn_data['box']\n",
        "  eqn_image = eqn_data['image']\n",
        "  graph_box = get_graph_box(img)\n",
        "  latex = image_to_latex(eqn_image)\n",
        "  return {'eqn_box': eqn_box, 'latex': latex, 'graph_box': graph_box}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import shutil\n",
        "# returns file path\n",
        "def generate_gif(graph_box, latex):\n",
        "\n",
        "  width = graph_box[1][0] - graph_box[0][0]\n",
        "  height = graph_box[1][1] - graph_box[1][0]\n",
        "  print('Removing dirs')\n",
        "  try:\n",
        "    shutil.rmtree('/content/media/videos/compiled_manim_scene')\n",
        "    print('Gone comp');\n",
        "  except:\n",
        "    pass\n",
        "  \n",
        "  try:\n",
        "    shutil.rmtree('/content/media/videos/manim_scene')\n",
        "    print('Gone normal')\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  with open('manim_scene.py', 'r') as fin:\n",
        "\n",
        "    s1 = re.sub(r\"\\'\\$\\$WIDTH\\$\\$\\'\", str(500), fin.read())\n",
        "    s2 = re.sub(r\"\\'\\$\\$HEIGHT\\$\\$\\'\", str(500), s1)\n",
        "    s3 = re.sub(r\"\\'\\$\\$TEX\\$\\$\\'\", \"'\" + latex + \"'\", s2)\n",
        "    with open('compiled_manim_scene.py', 'w') as fout:\n",
        "      fout.write(s3)\n",
        "  \"\"\"try:\n",
        "    shutil.rmtree('/content/media/videos/compiled_manim_scene/')\n",
        "  except:\n",
        "    pass\"\"\"\n",
        "  subprocess.run(['manim', 'compiled_manim_scene.py', 'Graph', '-r', '500,500', '-o', 'output.mp4', '--format=gif'])\n",
        "  path = f'/content/media/videos/compiled_manim_scene/{500}p60/output.gif'\n",
        "  \n",
        "  return path\n"
      ],
      "metadata": {
        "id": "KlyhbE2vtdBB"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "\n",
        "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
        "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
        "    # The ID of your GCS bucket\n",
        "    # bucket_name = \"your-bucket-name\"\n",
        "    # The path to your file to upload\n",
        "    # source_file_name = \"local/path/to/file\"\n",
        "    # The ID of your GCS object\n",
        "    # destination_blob_name = \"storage-object-name\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(destination_blob_name)\n",
        "\n",
        "    blob.upload_from_filename(source_file_name)\n",
        "\n",
        "    print(\n",
        "        f\"File {source_file_name} uploaded to {destination_blob_name}.\"\n",
        "    )"
      ],
      "metadata": {
        "id": "ZNkdaoJ1pvFy"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "8MMgSL3Ra9yh"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "import random\n",
        "import uuid\n",
        "import os\n",
        "import base64\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"credentials.json\" \n",
        "\n",
        "class Job(BaseModel):\n",
        "    base64: str\n",
        "\n",
        "app = FastAPI()\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=['*'],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=['*'],\n",
        "    allow_headers=['*'],\n",
        ")\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"Hello\": \"Welcome to the Anchor API\"}\n",
        "\n",
        "\n",
        "@app.post(\"/\")\n",
        "async def create_item(item: Job):\n",
        "    input_path = 'input.jpeg'\n",
        "    with open(input_path, \"wb\") as fh:\n",
        "        fh.write(base64.b64decode(item.base64))\n",
        "    data = get_latex('input.jpeg')  #return {'eqn_box': eqn_box, 'latex': latex, 'graph_box': graph_box}\n",
        "    gif_path = generate_gif(data['graph_box'], data['latex'])\n",
        "\n",
        "    data = get_latex('input.jpeg')  #return {'eqn_box': eqn_box, 'latex': latex, 'graph_box': graph_box}\n",
        "    print(data)\n",
        "    gif_path = generate_gif(data['graph_box'], data['latex'])\n",
        "    gif_location = str(uuid.uuid4())\n",
        "    img_location = str(uuid.uuid4())\n",
        "    final_gif_path = upload_blob('anchorgifs', gif_path, gif_location)\n",
        "    final_img_path = upload_blob('anchorgifs', input_path, img_location)\n",
        "    result = {'box': [int(data['graph_box'][0][1]),int(data['graph_box'][0][0]), int(data['graph_box'][1][1]), int(data['graph_box'][1][0])], 'gif': f'https://anchorgifs.storage.googleapis.com/{gif_location}', 'img': f'https://anchorgifs.storage.googleapis.com/{img_location}'}\n",
        "    print(result)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.set_auth_token('2FZC0hOsf6YkcyYGLy4A8814vCt_SuRuRgcURyhqi75whgQP')"
      ],
      "metadata": {
        "id": "sROTRKtCQcRk"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqrHXurdhj3X"
      },
      "outputs": [],
      "source": [
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}